{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3Ld_UBnb1FH"
      },
      "source": [
        "# Розмітка частин мови (Parts-of-Speech Tagging)\n",
        "\n",
        "У цій лабораторній роботі Ви познайомитеся з методом вирішення задачі розмітки частин мови (POS), а саме процесу присвоєння тегів частин мови (іменник, прикметник та ін.) словам у текстовому корпусі, за допомогою прихованої марковської моделі.\n",
        "\n",
        "Розмітка частин мови у тексті є доволі важливою для побудови високоточних пошукових систем, чат-ботів і діалогових агентів, а також алгоритмів автоматичного виправлення тексту.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFiPbkGIr-Iq"
      },
      "source": [
        "## Завантаження вихідних даних та програмного коду (опціонально)\n",
        "\n",
        "Для виконання цієї роботи необхідно мати повний архів, що містить файли Python з допоміжними функціями та окрему папку з підготовленим датасетом.\n",
        "\n",
        "Якщо у Вас з якихось причин є тільки цей ноутбук, Ви можете завантажити усі необхідні файли з GitHub за допомогою наступних команд:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqIlP2Dgb1wP",
        "outputId": "5a7228b4-aacb-4f05-affb-007fee2c82f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-07-22 00:03:22--  https://github.com/niksyromyatnikov/opnu-ml-assignments/archive/refs/heads/main.zip\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/niksyromyatnikov/opnu-ml-assignments/zip/refs/heads/main [following]\n",
            "--2024-07-22 00:03:22--  https://codeload.github.com/niksyromyatnikov/opnu-ml-assignments/zip/refs/heads/main\n",
            "Resolving codeload.github.com (codeload.github.com)... 140.82.113.10\n",
            "Connecting to codeload.github.com (codeload.github.com)|140.82.113.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘main.zip’\n",
            "\n",
            "main.zip                [  <=>               ]   2.46M  5.31MB/s    in 0.5s    \n",
            "\n",
            "2024-07-22 00:03:23 (5.31 MB/s) - ‘main.zip’ saved [2583327]\n",
            "\n",
            "Archive:  main.zip\n",
            "71d4ee037585e19d1071ccd131e8578a76080d20\n",
            "   creating: opnu-ml-assignments-main/\n",
            "   creating: opnu-ml-assignments-main/part-of-speech-tagging-with-hmm/\n",
            "   creating: opnu-ml-assignments-main/part-of-speech-tagging-with-hmm/data/\n",
            "  inflating: opnu-ml-assignments-main/part-of-speech-tagging-with-hmm/data/test_pos.txt  \n",
            "  inflating: opnu-ml-assignments-main/part-of-speech-tagging-with-hmm/data/test_predict.txt  \n",
            "  inflating: opnu-ml-assignments-main/part-of-speech-tagging-with-hmm/data/train_pos.txt  \n",
            "  inflating: opnu-ml-assignments-main/part-of-speech-tagging-with-hmm/data/vocab.txt  \n",
            "  inflating: opnu-ml-assignments-main/part-of-speech-tagging-with-hmm/data_helper.py  \n",
            "  inflating: opnu-ml-assignments-main/part-of-speech-tagging-with-hmm/eval_helper.py  \n",
            "  inflating: opnu-ml-assignments-main/part-of-speech-tagging-with-hmm/hmm_helper.py  \n",
            "  inflating: opnu-ml-assignments-main/part-of-speech-tagging-with-hmm/pos_helper.py  \n",
            " extracting: opnu-ml-assignments-main/part-of-speech-tagging-with-hmm/requirements.txt  \n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/niksyromyatnikov/opnu-ml-assignments/archive/refs/heads/main.zip && unzip main.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__hLsW83dvuW",
        "outputId": "3db974ea-20f8-4c30-a397-7aceaa522cd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/opnu-ml-assignments-main/part-of-speech-tagging-with-hmm\n"
          ]
        }
      ],
      "source": [
        "cd opnu-ml-assignments-main/part-of-speech-tagging-with-hmm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRK7uWUbvav6"
      },
      "source": [
        "## Підготовка середовища"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZisgXPmMb1FI",
        "outputId": "a5ad4194-2193-486b-e194-ef03e36f8815"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pandas==2.2.2 (from -r requirements.txt (line 1))\n",
            "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.26.4 (from -r requirements.txt (line 2))\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2->-r requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2->-r requirements.txt (line 1)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas==2.2.2->-r requirements.txt (line 1)) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas==2.2.2->-r requirements.txt (line 1)) (1.16.0)\n",
            "Installing collected packages: numpy, pandas\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.0.3\n",
            "    Uninstalling pandas-2.0.3:\n",
            "      Successfully uninstalled pandas-2.0.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 2.2.2 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.0.3, but you have pandas 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4 pandas-2.2.2\n"
          ]
        }
      ],
      "source": [
        "# Встановлення залежностей\n",
        "%pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EZMJcWutb1FJ"
      },
      "outputs": [],
      "source": [
        "# Імпорт бібліотек\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import math\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "from data_helper import load_data\n",
        "from hmm_helper import calculate_dicts, build_transitions, build_emissions\n",
        "from eval_helper import calculate_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHRlEgJzb1FJ"
      },
      "source": [
        "<a name='0'></a>\n",
        "## Вихідні дані\n",
        "У цій лабораторній роботі використовується розмічений набір даних **Wall Street Journal (WSJ)**.\n",
        "Опис та приклади наявних у датасеті тегів (частин мови) можна переглянути за [посиланням](http://relearn.be/2015/training-common-sense/sources/software/pattern-2.6-critical-fork/docs/html/mbsp-tags.html).\n",
        "\n",
        "\n",
        "Тренувальний набір `train_pos.txt` використовується для побудови матриць переходів та виходів, а також для обчислення кількості входжень тегів.\n",
        "\n",
        "Словник `vocab.txt` містить унікальні слова, що зустрічаються у датасеті більше одного разу.\n",
        "\n",
        "Тестовий набір зі словами та тегами наведено у `test_pos.txt`, він використовується для оцінки точності передбачення.\n",
        "\n",
        "Для передбачення використовується окремий файл `test_predict.txt`, що представляє собою тестовий набір без тегів."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oeRzRy3b1FJ",
        "outputId": "59a43bf3-6199-4732-90cf-cf8a0dc0c5b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Перші 20 рядків тренувального набору:\n",
            "['In\\tIN\\n', 'an\\tDT\\n', 'Oct.\\tNNP\\n', '19\\tCD\\n', 'review\\tNN\\n', 'of\\tIN\\n', '``\\t``\\n', 'The\\tDT\\n', 'Misanthrope\\tNN\\n', \"''\\t''\\n\", 'at\\tIN\\n', 'Chicago\\tNNP\\n', \"'s\\tPOS\\n\", 'Goodman\\tNNP\\n', 'Theatre\\tNNP\\n', '(\\t(\\n', '``\\t``\\n', 'Revitalized\\tVBN\\n', 'Classics\\tNNS\\n', 'Take\\tVBP\\n']\n",
            "\n",
            "\n",
            "Перші 20 елементів з файлу словника: ['!', '#', '$', '%', '&', \"'\", \"''\", \"'40s\", \"'60s\", \"'70s\", \"'80s\", \"'86\", \"'90s\", \"'N\", \"'S\", \"'d\", \"'em\", \"'ll\", \"'m\", \"'n'\"]\n",
            "Останні 20 елементів з файлу словника: ['youngsters', 'your', 'yourself', 'youth', 'youthful', 'yuppie', 'yuppies', 'zero', 'zero-coupon', 'zeroing', 'zeros', 'zinc', 'zip', 'zombie', 'zone', 'zones', 'zoning', '{', '}', '']\n",
            "\n",
            "Перші 20 елементів словника:\n",
            "Ключ: Значення\n",
            ": 0\n",
            "!: 1\n",
            "#: 2\n",
            "$: 3\n",
            "%: 4\n",
            "&: 5\n",
            "': 6\n",
            "'': 7\n",
            "'40s: 8\n",
            "'60s: 9\n",
            "'70s: 10\n",
            "'80s: 11\n",
            "'86: 12\n",
            "'90s: 13\n",
            "'N: 14\n",
            "'S: 15\n",
            "'d: 16\n",
            "'em: 17\n",
            "'ll: 18\n",
            "'m: 19\n",
            "'n': 20\n",
            "\n",
            "\n",
            "Перші 20 рядків тестового набору:\n",
            "['The\\tDT\\n', 'economy\\tNN\\n', \"'s\\tPOS\\n\", 'temperature\\tNN\\n', 'will\\tMD\\n', 'be\\tVB\\n', 'taken\\tVBN\\n', 'from\\tIN\\n', 'several\\tJJ\\n', 'vantage\\tNN\\n', 'points\\tNNS\\n', 'this\\tDT\\n', 'week\\tNN\\n', ',\\t,\\n', 'with\\tIN\\n', 'readings\\tNNS\\n', 'on\\tIN\\n', 'trade\\tNN\\n', ',\\t,\\n', 'output\\tNN\\n']\n",
            "\n",
            "\n",
            "Перші 20 елементів набору для передбачення:\n",
            "['The', 'economy', \"'s\", 'temperature', 'will', 'be', 'taken', 'from', 'several', '--unk--', 'points', 'this', 'week', ',', 'with', 'readings', 'on', 'trade', ',', 'output']\n"
          ]
        }
      ],
      "source": [
        "# Завантаження вихідних даних\n",
        "train_corpus, y, vocab, prep = load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kMphx7Jb1FK"
      },
      "source": [
        "<a name='1'></a>\n",
        "# 1. Розмітка частин мови: Тренування"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAT8myY4b1FK"
      },
      "source": [
        "#### Число переходів\n",
        "- `transition_counter` - словник, який обчислює, скільки разів кожен тег зустрічається після іншого тегу.\n",
        "\n",
        "Він використовується для обчислення ймовірності появи тегу на позиції $i$ з урахуванням тегу на позиції $i-1$:\n",
        "$$P(t_i |t_{i-1}) \\tag{1}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_sQSz6yb1FK"
      },
      "source": [
        "#### Число виходів\n",
        "\n",
        "`emission_counter` - словник, який обчислює, скільки разів кожне слово зустічається для кожного тегу.\n",
        "\n",
        "Він використовується для обчислення ймовірності появи слова з урахуванням його тегу (виходу тегів у слова):\n",
        "$$P(w_i|t_i)\\tag{2}$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKuhSYPIb1FK"
      },
      "source": [
        "#### Число тегів\n",
        "\n",
        "`tag_counter` - словник, де ключем є тег, а значенням - кількість його появ у текстовому корпусі."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TK2jOz4Yb1FK",
        "outputId": "81cd383c-7405-4978-8f66-94d1e68f3232"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "оброблено 100000 елементів\n",
            "оброблено 200000 елементів\n",
            "оброблено 300000 елементів\n",
            "оброблено 400000 елементів\n",
            "оброблено 500000 елементів\n",
            "оброблено 600000 елементів\n",
            "оброблено 700000 елементів\n",
            "оброблено 800000 елементів\n",
            "оброблено 900000 елементів\n"
          ]
        }
      ],
      "source": [
        "emission_counter, transition_counter, tag_counter = calculate_dicts(train_corpus, vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDCN3t75b1FK",
        "outputId": "949e4105-b2a7-48f8-b995-b0bc47f0b691"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Число тегів (частин мови): 46\n",
            "Список тегів (частин мови): ['#', '$', \"''\", '(', ')', ',', '--s--', '.', ':', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB', '``']\n"
          ]
        }
      ],
      "source": [
        "states = sorted(tag_counter.keys())\n",
        "print(f\"Число тегів (частин мови): {len(states)}\")\n",
        "print(f\"Список тегів (частин мови): {states}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_0vhca_b1FL",
        "outputId": "e0a59af2-513b-45ec-aa5c-9b3e503d5285"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Приклад переходів у словнику transition_counter:\n",
            "(('--s--', 'IN'), 5050)\n",
            "(('IN', 'DT'), 32364)\n",
            "(('DT', 'NNP'), 9044)\n",
            "(('NNP', 'CD'), 1752)\n",
            "(('CD', 'NN'), 7377)\n",
            "(('NN', 'IN'), 32885)\n",
            "(('IN', '``'), 546)\n",
            "(('``', 'DT'), 1014)\n",
            "(('DT', 'NN'), 38873)\n",
            "(('NN', \"''\"), 686)\n",
            "((\"''\", 'IN'), 591)\n",
            "(('IN', 'NNP'), 14753)\n",
            "(('NNP', 'POS'), 5094)\n",
            "(('POS', 'NNP'), 905)\n",
            "(('NNP', 'NNP'), 34465)\n",
            "(('NNP', '('), 313)\n",
            "(('(', '``'), 42)\n",
            "(('``', 'VBN'), 75)\n",
            "(('VBN', 'NNS'), 759)\n",
            "(('NNS', 'VBP'), 5076)\n",
            "\n",
            "\n",
            "Приклад виходів у словнику emission_counter:\n",
            "(('IN', 'In'), 1735)\n",
            "(('DT', 'an'), 3142)\n",
            "(('NNP', 'Oct.'), 317)\n",
            "(('CD', '19'), 100)\n",
            "(('NN', 'review'), 36)\n",
            "(('IN', 'of'), 22925)\n",
            "(('``', '``'), 6967)\n",
            "(('DT', 'The'), 6795)\n",
            "(('NN', 'Misanthrope'), 3)\n",
            "((\"''\", \"''\"), 6787)\n",
            "(('IN', 'at'), 4361)\n",
            "(('NNP', 'Chicago'), 197)\n",
            "(('POS', \"'s\"), 8079)\n",
            "(('NNP', 'Goodman'), 7)\n",
            "(('NNP', 'Theatre'), 5)\n",
            "(('(', '('), 1153)\n",
            "(('VBN', '--unk_upper--'), 93)\n",
            "(('NNS', '--unk_upper--'), 350)\n",
            "(('VBP', 'Take'), 1)\n",
            "(('DT', 'the'), 41098)\n"
          ]
        }
      ],
      "source": [
        "limit = 20\n",
        "print(\"Приклад переходів у словнику transition_counter:\")\n",
        "for idx, tc in enumerate(transition_counter.items()):\n",
        "    if idx == limit:\n",
        "        break\n",
        "    print(tc)\n",
        "\n",
        "print(\"\\n\\nПриклад виходів у словнику emission_counter:\")\n",
        "for idx, ec in enumerate(emission_counter.items()):\n",
        "    if idx == limit:\n",
        "        break\n",
        "    print(ec)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fHVU3Wbb1FL"
      },
      "source": [
        "<a name='2'></a>\n",
        "# 2. Прихована марковська модель для розмітки частин мови\n",
        "\n",
        "Марковська модель містить ряд станів і ймовірностей переходу між цими станами (частинами мови).\n",
        "- Марковська модель використовує матрицю переходів `T`.\n",
        "- Прихована марковська модель додає матрицю виходів `E`, що описує ймовірність виходу до спостереження (слова), коли ми перебуваємо в певному стані (частина мови)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8VDu56Rb1FL"
      },
      "source": [
        "<a name='2.1'></a>\n",
        "## 2.1 Побудова матриць\n",
        "\n",
        "### Побудова матриці переходів T\n",
        "\n",
        "Нижче наведено приклад спрощеної до 5 тегів матриці переходів T.\n",
        "Кожна комірка матриці містить обчислену ймовірність переходу від одного тегу (частини мови) до іншого.\n",
        "Для кожної частини мови (рядок) наступна обирається із доступних стовпців, тому сума ймовірностей кожного рядка має дорівнювати 1.\n",
        "\n",
        "|**T**    |....|         NN   |          JJ  |         TO   |      VB      |          .  | ...|\n",
        "|---------|----|--------------|--------------|--------------|--------------|-------------|----|\n",
        "|**NN**   | ...| 0.122172     | 0.008786     | 0.039538     | 0.001399     | 0.109023    | ...|\n",
        "|**JJ**   | ...| 0.450038     | 0.074669     | 0.027884     | 0.000114     | 0.024389    | ...|\n",
        "|**TO**   | ...| 0.032831     | 0.030908     | 0.000090     | 0.574808     | 0.000760    | ...|\n",
        "|**VB**   | ...| 0.061616     | 0.084651     | 0.043384     | 0.004917     | 0.024208    | ...|\n",
        "|**.**    | ...| 0.000329     | 0.000101     | 0.000025     | 0.000177     | 0.000177    | ...|\n",
        "| ...     | ...|     ...      |     ...      |     ...      |     ...      |     ...     | ...|\n",
        "\n",
        "\n",
        "Для обчислення значень матриці використовується наступна формула:\n",
        "\n",
        "$$ P(t_i | t_{i-1}) = \\frac{C(t_{i-1}, t_{i}) + \\alpha }{C(t_{i-1}) +\\alpha * N}\\tag{3}$$\n",
        "\n",
        "- $N$ - загальна кількість тегів\n",
        "- $C(t_{i-1}, t_{i})$ - кількість появ переходу (попередній тег, поточний тег) у словнику `transition_counter`.\n",
        "- $C(t_{i-1})$ - кількість появ попереднього тегу у словнику `tag_counter`.\n",
        "- $\\alpha$ - параметр згладжування."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtPu9ub6b1FL",
        "outputId": "ed692f4d-84ed-49d6-9670-8f1babb8de1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Часткова матриця переходів T\n",
            "          NN        JJ        TO        VB         .\n",
            "NN  0.122172  0.008786  0.039538  0.001399  0.109023\n",
            "JJ  0.450038  0.074669  0.027884  0.000114  0.024389\n",
            "TO  0.032831  0.030908  0.000090  0.574808  0.000760\n",
            "VB  0.061616  0.084651  0.043384  0.004917  0.024208\n",
            ".   0.000329  0.000101  0.000025  0.000177  0.000177\n"
          ]
        }
      ],
      "source": [
        "T = build_transitions(transition_counter, tag_counter)\n",
        "\n",
        "state_names = [\"NN\", \"JJ\", \"TO\", \"VB\", \".\"]\n",
        "states_idxs = [states.index(x) for x in state_names]\n",
        "\n",
        "print(\"Часткова матриця переходів T\")\n",
        "T_sub = pd.DataFrame(np.vstack([T[idx, states_idxs] for idx in states_idxs]), index=state_names, columns=state_names)\n",
        "print(T_sub)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMpfpy7Xb1FL"
      },
      "source": [
        "### Побудова матриці виходів E\n",
        "\n",
        "Матриця виходів E має розмірність (num_tags, N), де num_tags - число можливих тегів (частин мови)\n",
        "\n",
        "Нижче наведено приклад спрощеної до 5 слів матриці виходів E.\n",
        "\n",
        "|**E**   | ...|  statistical   |        model   |    predicted    |     word        |           .    | ...|\n",
        "|----    |----|----------------|----------------|-----------------|-----------------|----------------|----|\n",
        "|**NN**  | ...| 7.521128e-09   |**3.459794e-04**| 7.521128e-09    |**3.384583e-04** | 7.521128e-09   | ...|\n",
        "|**JJ**  | ...|**1.959642e-04**| 3.267431e-05   | 1.632899e-08    | 1.632899e-08    | 1.632899e-08   | ...|\n",
        "|**TO**  | ...| 4.468120e-08   | 4.468120e-08   | 4.468120e-08    | 4.468120e-08    | 4.468120e-08   | ...|\n",
        "|**VB**  | ...| 3.779036e-08   | 3.782815e-05   | 3.779036e-08    | 3.779036e-08    | 3.779036e-08   | ...|\n",
        "|**VBD** | ...| 3.343053e-08   | 3.343053e-08   |**1.537838e-03** | 3.343053e-08    | 3.343053e-08   | ...|\n",
        "|**.**   | ...| 2.531532e-08   | 2.531532e-08   | 2.531532e-08    | 2.531532e-08    |**9.878037e-01**| ...|\n",
        "| ...    | ...|     ...        |     ...        |     ...         |     ...         |     ...        | ...|\n",
        "\n",
        "Для обчислення значень матриці використовується наступна формула:\n",
        "\n",
        "$$P(w_i | t_i) = \\frac{C(t_i, word_i)+ \\alpha}{C(t_{i}) +\\alpha * N}\\tag{4}$$\n",
        "\n",
        "- $C(t_i, word_i)$ - число разів, коли слово $word_i$ зустрічалось з тегом $tag_i$ в тренувальному наборі.\n",
        "- $C(t_i)$ - число разів, коли тег $tag_i$ зустрічався у тренувальному наборі.\n",
        "- $N$ - число слів у словнику.\n",
        "- $\\alpha$ - параметр згладжування."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ur3T43lbb1FL",
        "outputId": "f10c1a58-b16e-4d9a-bca6-c96bee1dca0f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      statistical         model     predicted          word             .\n",
            "NN   7.521128e-09  3.459794e-04  7.521128e-09  3.384583e-04  7.521128e-09\n",
            "JJ   1.959642e-04  3.267431e-05  1.632899e-08  1.632899e-08  1.632899e-08\n",
            "TO   4.468120e-08  4.468120e-08  4.468120e-08  4.468120e-08  4.468120e-08\n",
            "VB   3.779036e-08  3.782815e-05  3.779036e-08  3.779036e-08  3.779036e-08\n",
            "VBD  3.343053e-08  3.343053e-08  1.537838e-03  3.343053e-08  3.343053e-08\n",
            ".    2.531532e-08  2.531532e-08  2.531532e-08  2.531532e-08  9.878037e-01\n"
          ]
        }
      ],
      "source": [
        "E = build_emissions(emission_counter, tag_counter, list(vocab))\n",
        "\n",
        "# Демонстрація ймовірностей виходів матриці E для обраних слів та тегів\n",
        "words_to_check  = [\"statistical\", \"model\", \"predicted\", \"word\", \".\"]\n",
        "cols = [vocab[a] for a in words_to_check]\n",
        "row_names =[\"NN\", \"JJ\", \"TO\", \"VB\", \"VBD\", \".\"]\n",
        "rows = [states.index(a) for a in row_names]\n",
        "E_sub = pd.DataFrame(E[np.ix_(rows,cols)], index=row_names, columns=words_to_check )\n",
        "print(E_sub)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1b4nAq5b1FM"
      },
      "source": [
        "<a name='3'></a>\n",
        "# 3. Алгоритм Вітербі\n",
        "\n",
        "Реалізація алгоритму Вітербі, що є алгоритмом динамічного програмування, складається з трьох основних етапів:\n",
        "\n",
        "* **Ініціалізація** - на цьому етапі ініціалізуються матриці `best_paths` та `best_probabilities`, що потім використовуються для прямого проходження.\n",
        "* **Пряме проходження** - на кожній ітерації прямого проходження обчислюється ймовірність кожного шляху (послідовність тегів) та найкращих шляхів до цієї ітерації.\n",
        "* **Зворотне проходження** - цей етап використовується для пошуку найкращого (найімовірнішого) шляху (послідовності тегів)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMpifY2Tb1FM"
      },
      "source": [
        "<a name='3.1'></a>\n",
        "## 3.1 Завдання: імплементація етапу ініціалізації\n",
        "\n",
        "Необхідно ініціалізувати дві матриці однакової розмірності.\n",
        "\n",
        "- `best_probs`: кожна комірка містить ймовірність переходу від одного тегу (частини мови) до слова у корпусі.\n",
        "\n",
        "- `best_paths`: матриця, яка використовується для визначення найкращого можливого шляху.\n",
        "\n",
        "Обидві матриці потрібно заповнити нулями, за винятком нульового стовпця `best_probs`.\n",
        "Нульовий стовпець `best_probs` заповнюється з припущенням, що першому слову корпусу передує початковий токен (\"--s--\").\n",
        "\n",
        "Ініціалізація нульового стовпця `best_probs` відбувається наступним чином:\n",
        "- Імовірність найкращого шляху від початкового індексу до заданого тегу з індексом $i$ позначається як best_probs$[s_{idx}, i]$.\n",
        "- Це оцінюється як ймовірність того, що початковий тег переходить до тегу з індексом $i$ $\\mathbf{T}[s_{idx}, i]$ і що тег з індексом $i$ виходить у перше слово корпусу $ \\mathbf{E}[i, vocab[corpus[0]]] $.\n",
        "\n",
        "Математична форма запису:\n",
        "best_probs$[s_{idx}, i] = \\mathbf{T}[s_{idx}, i] \\times \\mathbf{E}[i, corpus[0] ]$\n",
        "\n",
        "\n",
        "Для уникнення множення та малих значень ми беремо логарифм добутку, що стає сумою двох логарифмів:\n",
        "\n",
        "best_probs$[i, 0] = log(T[s_{idx}, i]) + log(E[i, vocab[corpus[0]]])$\n",
        "\n",
        "Крім того, щоб уникнути логарифм 0, best_probs$[i, 0] = float('-inf')$ коли $T[s_{idx}, i] == 0$\n",
        "\n",
        "<br>\n",
        "\n",
        "Отже, реалізація ініціалізації `best_probs` має такий вигляд:\n",
        "\n",
        "Якщо $T[s_{idx}, i] <> 0$ тоді best_probs$[i,0] = log(T[s_{idx}, i]) + log(E[i, vocab[corpus[0]]])$\n",
        "\n",
        "Якщо $T[s_{idx}, i] == 0$ тоді best_probs$[i,0] = float('-inf')$\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "*Для логарифму використовуйте [math.log](https://docs.python.org/3/library/math.html)\n",
        "\n",
        "**Представляйте нескінченність і негативну нескінченність так:\n",
        "\n",
        "```CPP\n",
        "float('inf')\n",
        "float('-inf')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_LAUN0QOb1FM"
      },
      "outputs": [],
      "source": [
        "def initialize(\n",
        "    states: List[str],\n",
        "    tag_counter: Dict[str, int],\n",
        "    T: List[List[float]],\n",
        "    E: List[List[float]],\n",
        "    corpus: List[str],\n",
        "    vocab: Dict[str, int]\n",
        ") -> Tuple[List[List[float]], List[List[int]]]:\n",
        "    \"\"\"\n",
        "    states: список усіх тегів (частин мови)\n",
        "    tag_counter: словник, де тег є ключем, а число його появи у наборі - значенням\n",
        "    T: матриця переходів розмірністю tags_total x tags_total\n",
        "    E: матриця виходів розмірністю (tags_total, len(vocab))\n",
        "    corpus: послідовність слів для ідентифікації тегів\n",
        "    vocab: словник, де слово є ключем, а індекс - значенням\n",
        "\n",
        "    proba_best: матриця розмірністю (tags_total, len(corpus))\n",
        "    path_best: матриця розмірністю (tags_total, len(corpus))\n",
        "    \"\"\"\n",
        "    \n",
        "    # Реалізуйте функцію тут\n",
        "\n",
        "    return proba_best, path_best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rwdRh-0Bb1FM"
      },
      "outputs": [],
      "source": [
        "proba_best, path_best = initialize(states, tag_counter, T, E, prep, vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftt1HKyRb1FM",
        "outputId": "a7e934eb-b91d-4357-bb16-e06e6776c9fb"
      },
      "outputs": [],
      "source": [
        "print(f\"proba_best[0,0]: {proba_best[0, 0]:.4f}\")\n",
        "print(f\"path_best[2,3]: {path_best[2, 3]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiEQAX5Gb1FM"
      },
      "source": [
        "<a name='3.2'></a>\n",
        "## 3.2 Завдання: імплементація етапу прямого проходження\n",
        "\n",
        "У цьому завданні необхідно реалізувати логіку заповнення матриць `best_probs` та `best_paths`:\n",
        "\n",
        "Формули для обчислення ймовірності та шляху для слова з індексом $i$ у $corpus$:\n",
        "\n",
        "$\\mathrm{prob} = \\mathbf{best\\_prob}[k, i-1] + \\mathrm{log}(\\mathbf{T}[k, j]) + \\mathrm{log}(\\mathbf{E}[j, vocab[corpus[i] ] ) ]$\n",
        "\n",
        "де $i-1$ - індекс попереднього слова у корпусі, $j$ - індекс поточного тегу, а $k$ - індекс попереднього тегу\n",
        "\n",
        "$\\mathrm{path} = k$\n",
        "\n",
        "де $k$ — ціле число, що представляє попередній тег.\n",
        "\n",
        "<br>\n",
        "\n",
        "Реалізуйте етап прямого проходження `forward()` для обчислення `best_path` і `best_prob` для кожного тегу і кожного слова, використовуючи наведений нижче псевдокод.\n",
        "\n",
        "```\n",
        "для кожного слова у корпусі\n",
        "\n",
        "    для кожного тегу_j (частини мови), що може зустрічатися з цим словом\n",
        "    \n",
        "        для кожного тегу_k, що може зустрічатися з попереднім словом\n",
        "\n",
        "            обчислити ймовірність того, що попереднє слово мало тег_k, поточне слово має тег_j, а також тег_j виходить у поточне слово\n",
        "            \n",
        "            зберегти найбільшу ймовірність обчислену для поточного слова\n",
        "\n",
        "            занести найбільшу ймовірність у матрицю `best_probs`\n",
        "\n",
        "            занести індекс `k`, що ідентифікує тег попереднього слова та з яким було отримано найбільшу ймовірність, у матрицю `best_paths`\n",
        "```\n",
        "\n",
        "<br>\n",
        "\n",
        "*Для логарифму використовуйте [math.log](https://docs.python.org/3/library/math.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Q3_M_5sXb1FM"
      },
      "outputs": [],
      "source": [
        "def forward(\n",
        "    T: List[List[float]],\n",
        "    E: List[List[float]],\n",
        "    test_corpus: List[str],\n",
        "    proba_best: List[List[float]],\n",
        "    path_best: List[List[float]],\n",
        "    vocab: Dict[str, int]\n",
        ") -> Tuple[List[List[float]], List[List[int]]]:\n",
        "    \"\"\"\n",
        "    T: матриця переходів розмірністю tags_total x tags_total\n",
        "    E: матриця виходів розмірністю (tags_total, len(vocab))\n",
        "    test_corpus: підготовлений тестовий корпус у вигляді списку cлів\n",
        "    proba_best: ініціалізована матриця розмірністю (tags_total, len(corpus))\n",
        "    path_best: ініціалізована матриця розмірністю (tags_total, len(corpus))\n",
        "    vocab: словник, де слово є ключем, а індекс - значенням\n",
        "\n",
        "    proba_best: ініціалізована матриця розмірністю (tags_total, len(corpus))\n",
        "    path_best: ініціалізована матриця розмірністю (tags_total, len(corpus))\n",
        "    \"\"\"\n",
        "    \n",
        "    # Реалізуйте функцію тут\n",
        "\n",
        "    return proba_best, path_best"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbyKIcRzb1FN",
        "outputId": "0ace32f4-7511-42bd-ecbc-6b979a8bd02f"
      },
      "outputs": [],
      "source": [
        "proba_best, path_best = forward(T, E, prep, proba_best, path_best, vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sv9KRJYJb1FN",
        "outputId": "4522b46a-9622-4009-b9ea-35dd3f300ca1"
      },
      "outputs": [],
      "source": [
        "print(f\"proba_best for word {prep[1]}:\")\n",
        "for tag, proba in zip(states, proba_best[:, 1].tolist()):\n",
        "    print(tag, proba)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5j5yZ5nb1FN"
      },
      "source": [
        "<a name='3.3'></a>\n",
        "## 3.3 Завдання: імплементація зворотного поширення\n",
        "\n",
        "У цьому завданні необхідно імплементувати метод зворотного поширення `backward()` для алгоритму Вітербі, що для кожного слова з текстового корпусу передбачує тег (частину мови) за допомогою обчислених раніше матриць `best_paths` та `best_probs`.\n",
        "\n",
        "Метод складається з двох кроків:\n",
        "1. Пройти кожен рядок (тег) для останнього стовпця (останнього слова у корпусі) матриці `best_probs` та визначити індекс рядку (тегу) з найбільшим значенням. Конвертувати індекс у тег та зберегти його у списку передбачення.\n",
        "2. Знайти найімовірніший тег для попереднього слова за допомогою отриманого індексу для поточного (останнього) слова та матриці `best_paths`. Записати отриманий тег у список передбачень та повторити крок для усіх попередніх слів."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "r_slM6eOb1FN"
      },
      "outputs": [],
      "source": [
        "def backward(\n",
        "    proba_best: List[List[float]],\n",
        "    path_best: List[List[float]],\n",
        "    corpus: List[str],\n",
        "    states: List[str]\n",
        ") -> List[str]:\n",
        "    \"\"\"\n",
        "    proba_best: ініціалізована матриця розмірністю (tags_total, len(corpus))\n",
        "    path_best: ініціалізована матриця розмірністю (tags_total, len(corpus))\n",
        "    corpus: підготовлений тестовий корпус у вигляді списку cлів\n",
        "    states: список усіх тегів (частин мови)\n",
        "\n",
        "    pred: список тегів розмірністю len(corpus), де кожний тег є передбаченням\n",
        "    для відповідного слова у корпусі\n",
        "    \"\"\"\n",
        "    \n",
        "    # Реалізуйте функцію тут\n",
        "\n",
        "    return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExOlesNbb1FN",
        "outputId": "4e983888-e844-44e0-ee84-9b0b646ff9e4"
      },
      "outputs": [],
      "source": [
        "pred = backward(proba_best, path_best, prep, states)\n",
        "\n",
        "limit = 200\n",
        "curr_i = 0\n",
        "print(\"Word | True | Pred\")\n",
        "for ground_truth, pred_tag in zip(y, pred):\n",
        "    if curr_i > limit:\n",
        "        break\n",
        "    curr_i += 1\n",
        "    word_and_tag = ground_truth.replace('\\n', '').split('\\t')\n",
        "    print(word_and_tag[0], '|', word_and_tag[1] if len(word_and_tag) == 2 else ' --s--', '|', pred_tag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjpvjB-9b1FN"
      },
      "source": [
        "<a name='4'></a>\n",
        "# 4. Оцінка точності\n",
        "\n",
        "Обчисліть точність свого прогнозу, порівнявши передбачення `pred` з правильними тегами `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6xZnjRnb1FN",
        "outputId": "d483120d-de2e-470c-e783-87e3e85d8d79"
      },
      "outputs": [],
      "source": [
        "print(f\"Точність: {calculate_accuracy(pred, y):.4f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "coursera": {
      "schema_names": [
        "NLPC2-2"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
